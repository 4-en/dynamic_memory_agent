# The Hugging Face model to use
# Set hf_repo to 'local' to use a local model
hf_repo=unsloth/Qwen3-14B-GGUF
hf_file=*Q4_K_M.gguf
# The Hugging Face tokenizer override, if any
hf_tokenizer_override=Qwen/Qwen3-14B-FP8
# The instruction to use for the LLM
llm_instruction=You are a helpful assistant.
# The settings for the underlying LLM.
llm_max_tokens_gen=-1
llm_n_gpu_layers=-1
llm_n_ctx=40960
llm_flash_attn=True
llm_verbose=True
# The sampling settings for the LLM.
llm_temperature=0.7
llm_top_p=0.95
llm_top_k=40
# The method to use for context injection. Options are 'reasoning' or 'expert'.
context_injection_method=reasoning
